{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d841625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d95136",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"yolov7-tiny.weights\"  # weights file path\n",
    "config_path = \"yolov7-tiny.cfg\"      # configuration file path\n",
    "names_path = \"coco.names\"        # class names file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a62afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2037228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class names\n",
    "classNames = []\n",
    "if names_path:\n",
    "    with open(names_path, \"r\") as f:\n",
    "        classNames = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8762f5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd16778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model using OpenCV's dnn module\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451f2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect objects in a frame\n",
    "def detect_objects(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Blob from the frame for feeding into the YOLO model\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Get the output layers names from the YOLO network\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # Perform inference and get detections\n",
    "    outputs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize confidence threshold and non-maxima suppression (NMS) threshold\n",
    "    conf_threshold = 0.5\n",
    "    nms_thresh = 0.4\n",
    "\n",
    "    # Create lists for bounding boxes, confidences, and class IDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # Loop over the outputs of each layer\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            # Extract scores, class ID, and bounding box coordinates\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Filter detections by confidence threshold\n",
    "            if confidence > conf_threshold:\n",
    "                # Scale bounding box coordinates based on frame size\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                center_x, center_y, w, h = box.astype(int) \n",
    "                \n",
    "                # Get top left corner coordinates of the bounding box\n",
    "                x = int(center_x - (w / 2))\n",
    "                y = int(center_y - (h / 2))\n",
    "\n",
    "                boxes.append([x, y, int(w), int(h)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(int(class_id))\n",
    "\n",
    "    # Apply non-maxima suppression (NMS) to suppress weak, overlapping bounding boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_thresh)\n",
    "\n",
    "    # Draw detected objects and their labels on the frame\n",
    "    for i, idx in enumerate(indices):\n",
    "        box = boxes[idx]\n",
    "        x, y, w, h = box\n",
    "        label = str(classNames[class_ids[idx]]) if classNames else str(class_ids[idx])\n",
    "        confidence = confidences[idx]\n",
    "\n",
    "        color = (0, 255, 0)  # Green color for bounding box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(frame, label + \" \" + str(round(confidence * 100, 2)) + \"%\",\n",
    "                    (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "766ff1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start video capture (replace 0 for webcam or video file path)\n",
    "# cap = cv2.VideoCapture('D:\\OBJECT DETECTION\\species.mp4')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Detect objects in the frame\n",
    "    detected_frame = detect_objects(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Real-time Object Detection', detected_frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF== ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f78e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
